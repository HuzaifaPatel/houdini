\section{Introduction}

Container-based workloads have become a cornerstone of modern cloud infrastructure, revolutionizing how applications are developed, deployed, and scaled, particularly within microservices architectures and DevOps workflows. Unlike hypervisor-based virtual machines (VMs), which each require a full operating system and rely on a hypervisor for hardware virtualization, containers are lightweight, share the host system’s kernel, and incur minimal overhead. This efficiency makes them exceptionally well-suited for continuous integration and rapid scaling, allowing organizations to optimize resource utilization and reduce costs while ensuring quick, consistent deployments. Furthermore, containers enable seamless portability by packaging all userspace dependencies into a unified image, thereby avoiding the common problem of environment-specific discrepancies. Yet, despite containers’ numerous benefits, they also introduce new security challenges, especially where container confinement is concerned.

Linux kernel features such as cgroups, namespaces, and mount points provide resource, process, and network isolation for containers. However, this separation is not foolproof. Kernel vulnerabilities, such as buffer overflows or privilege escalation flaws can allow a process to circumvent the very mechanisms designed to confine it. Misconfigurations can similarly open holes in container security, for instance by granting unnecessary capabilities, mounting sensitive host directories, or running containers in privileged mode. Finally, sophisticated attacks like container escapes exploit these weaknesses to break out of the container’s resource and namespace isolation. Once an attacker gains elevated privileges or direct access to the host system, they can disrupt other containers, exfiltrate data, or compromise the entire infrastructure. Technologies like SELinux, AppArmor, and seccomp provide additional layers of security to avoid these issues, but are notoriously complex to configure and prone to misconfiguration. A best practices guide for container security  \cite{CIS} can help with configuring a container, but it offers no guarantee that the given configuration will perform as intended by the end-user. As container adoption skyrocketed across industries, particularly in multi-tenant cloud environments, these security challenges have become more pronounced.

To address the aforementioned challenges, the cloud industry has developed technologies like gVisor and Kata Containers \cite{sultan2019container}, which isolate containers further by running them within lightweight VMs. While this approach is effective, it unnecessarily increases complexity and overhead. By developing methods to audit and validate confinement mechanisms, container security could be simplified by reducing reliance on such solutions.

Test suites play a crucial role in verifying that systems meet specified requirements and function correctly under defined conditions. They are widely used across computing disciplines, from performance benchmarking to security assessment. For instance, the Standard Performance Evaluation Corporation (SPEC) \cite{henning2000spec} is best known for developing industry-standard benchmarks that evaluate CPU performance and power efficiency, while the Transaction Processing Performance Council (TPC) \cite{10.1007/978-3-642-18206-8_1} establishes benchmarking standards for database performance. The Phoronix Test Suite \cite{zboril2025performance} is a widely used benchmarking tool, particularly for Linux-based systems, providing automated performance evaluations across various hardware and software configurations. Other notable benchmarks include Geekbench, a cross-platform tool for assessing CPU and GPU performance, and IOzone, which specializes in file system I/O analysis.

Beyond performance testing, test suites are essential in software development to prevent regressions. Many organizations mandate that all code changes pass a comprehensive suite of tests before integration. In production environments, test suites help maintain reliability through uptime monitoring, ensuring that services remain operational. Additionally, specialized security-focused test suites play a vital role in detecting vulnerabilities in deployed systems. Tools such as network scanners aid in identifying misconfigurations, outdated software versions, and unintended service exposures, helping organizations proactively mitigate security risks.

Despite the widespread use of test suites in the aforementioned areas, a significant gap remains in the context of containers. There are currently no standardized or widely adopted test suites designed specifically to evaluate container confinement, functionality, or isolation effectiveness. This absence leaves organizations to rely on ad hoc methods, which are often inadequate for uncovering subtle misconfigurations or ensuring robust confinement. Given the growing reliance on containerized environments in modern infrastructure, the development of comprehensive test suites tailored for containers is imperative. Such test suites would not only address these critical gaps but also provide a reliable foundation for improving trust and security in containerized systems.

In this paper, we describe \houdini, the first test suite for verifying container confinement. Given a Docker container configuration (including both the kernel version and the docker version), \houdini will instantiate the container in a standalone QEMU-based VM and perform multiple tests (or tricks, as we call them) to evaluate whether the container is susceptible to various forms of misconfigurations or failures. These tests explore vulnerabilities that could disrupt container functionality, such as, but not limited to improper resource allocation, inadequate isolation, or insecure filesystem setups. Houdini is written in Python and is easily extensible, providing an extension language for writing tricks. \houdini is designed to assess and enhance the security of containerized environments. It tests the isolation of containers, ensuring they remain properly confined and separated from the host system and other containers. Houdini specializes in identifying container-specific vulnerabilities, misconfigurations, and ensuring adherence to security best practices.

A standard methodology for assessing container confinement is crucial due to the complexity of modern systems and the intricate vulnerabilities they present. A formal approach involving rigorously evaluating and analyzing the security of the container system might seem ideal, however, it is impractical because container environments are highly complex, with interactions between kernels, runtimes, orchestration tools, and external dependencies that are difficult to model comprehensively. Moreover, many vulnerabilities stem from subtle details that a formal model might overlook. Instead, an empirical approach offers a practical alternative. Though it will never be exhaustive, the goal is not comprehensive coverage but rather establishing a baseline set of tests that demonstrate effective container confinement. This approach is achievable and can evolve over time as new vulnerabilities are identified, allowing the methodology to remain current. Starting with tests for isolation, privilege escalation prevention, and resource limitation enforcement provides a solid foundation. By focusing on demonstrating security effectiveness in critical areas, this methodology can enhance confidence in container confinement while enabling continuous improvement and adaptation to the evolving threat landscape.

In this paper, we describe the motivation, design, and implementation of \houdini. We also present the results of case studies by showing how Houdini can be used to detect misconfigured containers. Our hope with Houdini is that it will help with the deployment of better confined containers and will support the development of new technologies to more reliably confine containers.

The rest of this paper proceeds as follows. In Section~\ref{sec:confinement}, we explain the container confinement problem and associated technologies. Section~\ref{sec:related} describes related work. In Section ~\ref{sec:linux-confinement-mechanisms}, we write about Linux confinment mechanisms. We describe Houdini's design in Section~\ref{sec:design}. We describe the implementation of \houdini in Section~\ref{sec:implementation}. We briefly describe the container attack surface analysis in Section~\ref{sec:container-attack-surface-analysis}. In Section~\ref{sec:evaluation} we present case studies showing how \houdini can detect basic misconfigurations, and explain the tricks \houdini currently implements and their associated vulnerabilities. Section~\ref{sec:conclusion} concludes our paper.


%% While containers are widely used, despite their name they don't currently offer strong confinement guarantees. Numerous ways for procesess inside a container to "escape".  While originally containers were designed for administration and software distribution purposes, there is increasing interest in improving container confinement.

%% Variety of solutions:
%% \begin{itemize}
%% \item host-based security mechanisms applied to enforce confinement on processes inside containers (SELinux, AppArmor, system call filters)
%% \item hardware virtualization applied to container confinement (gVisor, kata containers - also known as microVMs, )
%% \item new kernel-level security abstractions, often implemented in eBPF (bpfbox, bpfcontain on archive)
%% \end{itemize}

%% Our question: how effective are these container confinement solutions?

%% Needed: a standard methodology for assessing container confinement
%% \begin{itemize}
%% \item formal approach not feasible, systems are too complex and vulnerabilities are in the details
%% \item empirical approach is possible.  Will never be comprehensive, but that is not the goal.  Instead, we want a baseline set of tests (that can be improved over time) that demonstrates effective container confinement.
%% \end{itemize}

%% Contribution: Houdini, first tool for automated testing of container confinement
%% \begin{itemize}
%% \item series of tests for well-known container vulnerabilities
%% \item designed to facilitate repeatable experiments using qemu-based virtual machines
%% \item easily extensible to allow for new tests to be added, making Houdini more comprehensive over time
%% \end{itemize}
%% (NOTE: we should specify how to "version" Houdini so we can talk about both older and newer versions of Houdini.  So we don't just want a Houdini score, it should be a versioned Houdini score.)
