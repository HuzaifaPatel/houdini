\section{Introduction}

Container-based workloads have become a cornerstone of modern cloud infrastructure, which has revolutionized how applications are developed, deployed, and scaled. Unlike hypervisor-based virtual machines, which require a full operating system for each instance and rely on a hypervisor to manage hardware virtualization, containers are lightweight, share the host system’s kernel, and incur minimal overhead. This efficiency has made containers an attractive choice for organizations seeking to optimize resource utilization and reduce operational costs. Furthermore, containers enable seamless portability by encapsulating all userspace dependencies into a unified image. Despite container's numerous benefits, they introduce new security challenges, particularly around container confinement. 

We define container confinement as the set of mechanisms and strategies used to isolate a containerized application from the host system and other containers. Effective confinement is critical for maintaining system security and stability, as it ensures that containers operate within defined boundaries by restricting their access to system resources, processes, and networks. To confine a container means to enforce strict isolation between the container and the host system as well as between containers themselves, ensuring that the container operates within predefined boundaries without interfering with or compromising other containers or the host. The goal of container confinement is to limit the container’s access to system resources, prevent unauthorized actions, and ensure that it only interacts with the host environment in an optimal manner. Addressing this challenge is essential as the adoption of container technology continues to grow across industries.

Linux features such as cgroups, namespaces, and mountpoints create the appearance of isolation for containers. These mechanisms ensure that they are confined to their own resource, process, and network boundaries. However, this separation can fail due to kernel vulnerabilities, misconfigurations, or even sophisticated attacks like container escapes, allowing attackers to disrupt other containers or compromise the host system. Technologies like SELinux, AppArmor, and seccomp provide additional layers of security but are notoriously complex to configure and prone to misconfiguration. A best practices guide for container security  \cite{CIS} can help with configuring a container, but it offers no guarantee that the resulting configuration performs as intended. For instance, how can we confirm that cgroups and namespaces are restricting containers as intended? As container adoption skyrocketed across industries, particularly in multi-tenant cloud environments, these security challenges have become more pronounced. To address this challenge, the cloud industry has developed technologies like gVisor and Kata Containers, which isolate containers further by running them within lightweight virtual machines. While this approach is effective, it unnecessarily increases complexity and overhead. By developing methods to audit and validate confinement mechanisms, container security could be simplified by reducing reliance on such solutions.

Test suites play a crucial role in ensuring that systems meet requirements and function correctly under defined conditions. For instance, the SPEC (Standard Performance Evaluation Corporation) benchmarks measure CPU performance and power efficiency, while the TPC (Transaction Processing Performance Council) benchmarks assess database performance. The Phoronix Test Suite is another widely used option, particularly in Linux-based systems. Other notable benchmarks include Geekbench, a cross-platform tool for evaluating CPU and GPU performance, and IOzone, which focuses on file system I/O performance. In software development, regression tests play a critical role in ensuring that code changes do not inadvertently break existing functionality. Many organizations enforce policies requiring code to pass these tests before integration. Test suites also ensure the functionality of production systems, such as uptime monitors that verify whether services are operating as intended. Additionally, functional test suites, though less frequently used, help identify security vulnerabilities in deployed systems. Tools like network scanners are especially valuable for detecting misconfigurations, insecure software versions, and unintended service exposures.

Despite the widespread use of test suites in these areas, a significant gap remains in the context of containers. There are currently no standardized or widely adopted test suites designed specifically to evaluate container security, functionality, or isolation effectiveness. This absence leaves organizations relying on ad hoc methods, which are often inadequate for uncovering subtle vulnerabilities or ensuring robust confinement. Given the growing reliance on containerized environments in modern infrastructure, the development of comprehensive test suites tailored for containers is imperative. Such test suites would not only address these critical gaps but also provide a reliable foundation for improving trust and security in containerized systems.

In this paper, we describe the implementation of \houdini, the first test suite for verifying container confinement. Given a Docker container configuration (including both the kernel version and the docker version), Houdini will instantiate the container in a standalone QEMU-based virtual machine and perform multiple tests (or tricks, as we call them) to evaluate whether the configuration is susceptible to various forms of container misconfigurations or failures. These tests explore vulnerabilities that could disrupt container functionality, such as improper resource allocation, inadequate isolation, or insecure filesystem setups. Houdini is written in Python and is easily extensible, providing an extension language for writing tricks. Houdini is designed to assess and enhance the security of containerized environments. It tests the isolation of containers, ensuring they remain properly confined and separated from the host system and other containers. Houdini specializes in identifying container-specific vulnerabilities, misconfigurations, and ensuring adherence to security best practices.

A standard methodology for assessing container confinement is crucial due to the complexity of modern systems and the intricate vulnerabilities they present. This process requires some semantic knowledge about the system and is referred to as the semantic gap issue. This gap often arises because the mechanisms designed to secure a system (e.g., namespaces, cgroups, SELinux policies) may not always function as expected due to misconfigurations, lack of understanding, or emerging vulnerabilities. To bridge this semantic gap, a formal approach might seem ideal, however, it is impractical because container environments are highly complex, with interactions between kernels, runtimes, orchestration tools, and external dependencies that are difficult to model comprehensively. Moreover, many vulnerabilities stem from subtle details that a formal model might overlook. Instead, an empirical approach offers a practical alternative. Though it will never be exhaustive, the goal is not comprehensive coverage but rather establishing a baseline set of tests that demonstrate effective container confinement. This approach is achievable and can evolve over time as new vulnerabilities are identified, allowing the methodology to remain current. Starting with tests for isolation, privilege escalation prevention, resource limitation enforcement, and resistance to known exploits provides a solid foundation. By focusing on demonstrating security effectiveness in critical areas, this methodology can enhance confidence in container confinement while enabling continuous improvement and adaptation to the evolving threat landscape.

In this paper we describe Houdini's motivation, design, and implementation. We also present the results of case studies showing how Houdini can be used to detect misconfigured containers that allow for privilege escalation attacks on the host system. Our hope with Houdini is that it will help with the deployment of better confined containers and will support the development of new technologies to more reliably confine containers.

The rest of this paper proceeds as follows. In Section~\ref{sec:confinement}, we explain the container confinement problem and associated technologies.  We describe Houdini's design and implementation in Section~\ref{sec:design}. Section~\ref{sec:testing-confinement} explains the tricks Houdini currently implements and their associated vulnerabilities.  In Section~\ref{sec:evaluation} we present case studies showing how Houdini can detect basic misconfigurations.  Section~\ref{sec:related} describes related work, Section~\ref{sec:discussion} discusses the contributions, limitations, and our plans for future work.  Section~\ref{sec:conclusion} concludes.


%% While containers are widely used, despite their name they don't currently offer strong confinement guarantees. Numerous ways for procesess inside a container to "escape".  While originally containers were designed for administration and software distribution purposes, there is increasing interest in improving container confinement.

%% Variety of solutions:
%% \begin{itemize}
%% \item host-based security mechanisms applied to enforce confinement on processes inside containers (SELinux, AppArmor, system call filters)
%% \item hardware virtualization applied to container confinement (gVisor, kata containers - also known as microVMs, )
%% \item new kernel-level security abstractions, often implemented in eBPF (bpfbox, bpfcontain on archive)
%% \end{itemize}

%% Our question: how effective are these container confinement solutions?

%% Needed: a standard methodology for assessing container confinement
%% \begin{itemize}
%% \item formal approach not feasible, systems are too complex and vulnerabilities are in the details
%% \item empirical approach is possible.  Will never be comprehensive, but that is not the goal.  Instead, we want a baseline set of tests (that can be improved over time) that demonstrates effective container confinement.
%% \end{itemize}

%% Contribution: Houdini, first tool for automated testing of container confinement
%% \begin{itemize}
%% \item series of tests for well-known container vulnerabilities
%% \item designed to facilitate repeatable experiments using qemu-based virtual machines
%% \item easily extensible to allow for new tests to be added, making Houdini more comprehensive over time
%% \end{itemize}
%% (NOTE: we should specify how to "version" Houdini so we can talk about both older and newer versions of Houdini.  So we don't just want a Houdini score, it should be a versioned Houdini score.)
